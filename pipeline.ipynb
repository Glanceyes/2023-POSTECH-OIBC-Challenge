{"cells":[{"cell_type":"markdown","metadata":{"id":"7n_LIuqcYOpa"},"source":["# Notebook for Pipeline\n","\n","We present the whole pipeline of our methods in this jupyter notebook file other than data analysis.\n"]},{"cell_type":"markdown","metadata":{},"source":["## Before We Go"]},{"cell_type":"markdown","metadata":{},"source":["### Connect to Google Drive (Optional)\n","\n","> Note: We suppose that this code is executing on the Google Colab platform. The following code is used to import the libraries we need."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3332,"status":"ok","timestamp":1700553171833,"user":{"displayName":"오승옥","userId":"16243407126970040843"},"user_tz":-540},"id":"ApnL5Xo7YXXZ","outputId":"3c557d43-ffe8-42df-a388-d39a7fb30015"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{},"source":["### Import Libraries\n","    \n","Please run the following code to import the libraries we need."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FD_kDMAWYOpe"},"outputs":[],"source":["import os\n","from tqdm import tqdm\n","import torch\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{},"source":["## Data\n","\n","Details of the analysis data can be found in `EDA.ipynb`. We will not repeat them here.\n","\n","> Note: We cannot upload the original data file to the github repository because of copyright issues."]},{"cell_type":"markdown","metadata":{},"source":["### Dataset\n","\n","We need to define the dataset class to load the data. The dataset class is defined as follows."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DLG7O52CYOpg"},"outputs":[],"source":["class SunlightDataset(Dataset):\n","    def __init__(self, features, labels, window_size=2, step_size=1):\n","        self.features = torch.tensor(features.values, dtype=torch.float32)\n","        self.labels = torch.tensor(labels.values, dtype=torch.float32)\n","        self.window_size = window_size\n","        self.step_size = step_size\n","\n","    def __len__(self):\n","        total_steps = len(self.features) - self.window_size + 1\n","        # Calculate the number of complete windows that can be formed\n","        if total_steps > 0:\n","            return (total_steps + self.step_size - 1) // self.step_size\n","        else:\n","            return 0\n","\n","    def __getitem__(self, index):\n","        start = index * self.step_size\n","        end = start + self.window_size\n","\n","        return (self.features[start:end], self.labels[start:end])"]},{"cell_type":"markdown","metadata":{},"source":["> Note: The data is stored in the Google Drive. If you want to run the code, please change the path to your own path."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AguR8eaJYOph"},"outputs":[],"source":["# data = pd.read_csv('/content/drive/MyDrive/data10.csv')\n","data = pd.read_csv('/content/drive/MyDrive/data17.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A-bOQRsMYOpi"},"outputs":[],"source":["features = data.drop('amount', axis=1)\n","labels = data['amount']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d5GG0bsgYOpi"},"outputs":[],"source":["features_train, features_val, labels_train, labels_val = train_test_split(features, labels, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pjhg8WAqYOpj"},"outputs":[],"source":["train_dataset = SunlightDataset(features_train, labels_train)\n","val_dataset = SunlightDataset(features_val, labels_val)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1700553172611,"user":{"displayName":"오승옥","userId":"16243407126970040843"},"user_tz":-540},"id":"3RjfJR-IYOpj","outputId":"f142a675-4e88-4aef-83e5-1efaafca2ee0"},"outputs":[],"source":["len(train_dataset), len(val_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GAbInsyfYOpk"},"outputs":[],"source":["train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n","val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1700553172611,"user":{"displayName":"오승옥","userId":"16243407126970040843"},"user_tz":-540},"id":"e4tZEHm1YOpl","outputId":"4b17905c-09c7-4f36-ad98-8102a8af22fd"},"outputs":[],"source":["print(train_dataset[0])\n","print(train_dataset[0][0].shape)\n","print(train_dataset[0][1].shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1700553172612,"user":{"displayName":"오승옥","userId":"16243407126970040843"},"user_tz":-540},"id":"qjhHrs52YOpl","outputId":"5edfbe0b-7717-4a9e-efbd-90cdc05d84ae"},"outputs":[],"source":["train_features, train_labels = next(iter(train_loader))\n","print(train_features.shape)\n","print(train_labels.shape)"]},{"cell_type":"markdown","metadata":{"id":"IAPiXQWJYOpm"},"source":["## Model\n","\n","We should define the model class to train the model.\n","\n","> Note: Before defining the model class, please install related packages to ensure that the code can run normally."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4920,"status":"ok","timestamp":1700553177525,"user":{"displayName":"오승옥","userId":"16243407126970040843"},"user_tz":-540},"id":"LAJqG67hZH4-","outputId":"ba98a046-2eda-4076-af8a-ad948ded9083"},"outputs":[],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zk2q8IAqYOpm"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","from transformers.models.bert.modeling_bert import BertConfig, BertEncoder, BertModel"]},{"cell_type":"markdown","metadata":{},"source":["### LSTM with Attention\n","\n","We use the LSTM with Attention model to train the data. \n","\n","We implement not only the LSTM model but also Attention mechanism for making the model keep the long-term dependency and focus on the important part of the data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nWkxeh5_YOpn"},"outputs":[],"source":["class LSTMwithAttn(nn.Module):\n","\n","    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, num_heads=8, dropout=0.1, device='cpu'):\n","        super(LSTMwithAttn, self).__init__()\n","\n","        self.input_dim = input_dim\n","        self.hidden_dim = hidden_dim\n","        self.num_layers = num_layers\n","        self.output_dim = output_dim\n","        self.dropout = dropout\n","        self.device = device\n","\n","        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n","\n","        self.config = BertConfig(\n","            hidden_size=hidden_dim,\n","            num_hidden_layers=num_layers,\n","            num_attention_heads=num_heads,\n","            intermediate_size=hidden_dim,\n","            hidden_dropout_prob=dropout,\n","            attention_probs_dropout_prob=dropout,\n","        )\n","        self.encoder = BertEncoder(self.config)\n","\n","        self.act = nn.SiLU()\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","\n","        self.init_weights()\n","\n","\n","    def init_hidden_state(self, batch_size):\n","        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(self.device)\n","        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(self.device)\n","        return (h0, c0)\n","\n","\n","    def init_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Linear):\n","                nn.init.xavier_uniform_(m.weight)\n","                if m.bias is not None:\n","                    nn.init.zeros_(m.bias)\n","\n","\n","    def generate_attn_mask(self, x):\n","        seq_len = x.size(1)\n","        attn_mask = torch.tril(torch.ones((seq_len, seq_len))).view(1, seq_len, seq_len).to(self.device)\n","\n","        return attn_mask\n","\n","\n","    def forward(self, x):\n","        batch_size = x.size(0)\n","\n","        h0, c0 = self.init_hidden_state(batch_size)\n","\n","        output, (hidden, cell) = self.lstm(x, (h0, c0))\n","\n","        output = output.contiguous().view(batch_size, -1, self.hidden_dim)\n","\n","        # Attention Mask\n","        attn_mask = self.generate_attn_mask(x)\n","        extended_attn_mask = attn_mask[None, :, :, :].expand(batch_size, -1, -1, -1)\n","        extended_attn_mask = (1.0 - extended_attn_mask) * -10000.0\n","\n","        encoder_outputs = self.encoder(output, attention_mask=extended_attn_mask)\n","\n","        output = self.act(encoder_outputs.last_hidden_state)\n","        output = self.fc(output)\n","\n","        return output"]},{"cell_type":"markdown","metadata":{},"source":["> Note: We suppose that this code is running with GPU."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1700553177526,"user":{"displayName":"오승옥","userId":"16243407126970040843"},"user_tz":-540},"id":"AypKmtqCYOpn","outputId":"a2a3ef0e-f6dd-4392-800f-022baa2431bc"},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"]},{"cell_type":"markdown","metadata":{},"source":["## Training\n","\n","Below is the code for training the model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v4-N9T4qYOpn"},"outputs":[],"source":["model = LSTMwithAttn(input_dim=12, hidden_dim=64, output_dim=1, num_layers=2, device=device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9YZ3mN2XYOpo"},"outputs":[],"source":["model = model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9-OyIV3tYOpo"},"outputs":[],"source":["LEARNING_RATE = 0.001\n","EPOCHS = 100\n","WEIGHT_DECAY = 0.01\n","EARLY_STOPPING = 5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"958yzMj8YOpo"},"outputs":[],"source":["optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ve84QgyZYOpo"},"outputs":[],"source":["criterion = nn.MSELoss(reduction='mean')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MT4OaSnUYOpo"},"outputs":[],"source":["train_losses = []\n","val_losses = []\n","\n","loss = .0\n","best_val_loss = float('inf')\n","increasing_loss_count = 0"]},{"cell_type":"markdown","metadata":{},"source":["> Note: If we test the model without any training, initial loss would be very large."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":920,"status":"ok","timestamp":1700553178439,"user":{"displayName":"오승옥","userId":"16243407126970040843"},"user_tz":-540},"id":"uP6qsrQ0YOpo","outputId":"f3ff8d19-3ca6-46a7-c92b-e48ed3168f4f"},"outputs":[],"source":["model.eval()\n","\n","with torch.no_grad():\n","    for features, labels in val_loader:\n","        features = features.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = model(features)\n","\n","        _loss = criterion(outputs.squeeze(-1), labels)\n","\n","        loss += _loss.item()\n","\n","print(f'Initial Loss: {loss/len(val_loader):.4f}')"]},{"cell_type":"markdown","metadata":{},"source":["> Note: We can realize that the loss is decreasing as the training goes on. We also employ the early stopping mechanism to prevent overfitting."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47983,"status":"ok","timestamp":1700553226408,"user":{"displayName":"오승옥","userId":"16243407126970040843"},"user_tz":-540},"id":"5s4DNEvSYOpp","outputId":"f076fa98-9e5c-4108-fa86-63afc5fd4e2d"},"outputs":[],"source":["train_losses = []\n","val_losses = []\n","\n","for i in range(EPOCHS):\n","    print(\"=\" * 30)\n","    print(f\"Current Epoch {i+1}\")\n","    print(\"=\" * 30)\n","    print(\"Training...\")\n","    train_loss = .0\n","\n","    model.train()\n","    for features, labels in tqdm(train_loader, leave=False):\n","        features = features.to(device)\n","        labels = labels.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        outputs = model(features)\n","\n","        _loss = criterion(outputs.squeeze(-1), labels)\n","        _loss.backward()\n","        optimizer.step()\n","\n","        train_loss += _loss.item()\n","\n","\n","    print(\"Evaluating...\")\n","    val_loss = .0\n","\n","    model.eval()\n","\n","    for features, labels in tqdm(val_loader, leave=False):\n","        features = features.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = model(features)\n","\n","        _loss = criterion(outputs.squeeze(-1), labels)\n","\n","        val_loss += _loss.item()\n","\n","    train_losses += [train_loss/len(train_loader.dataset)]\n","    epoch_val_loss = val_loss/len(val_loader.dataset)\n","    val_losses += [epoch_val_loss]\n","    print(f\"Epoch #{i+1}: [Training MSE/Evaluation MSE]: [{train_loss/len(train_loader.dataset):.4f}/{val_loss/len(val_loader.dataset):.4f}]\")\n","\n","    if epoch_val_loss < best_val_loss:\n","        best_val_loss = epoch_val_loss\n","        increasing_loss_count = 0\n","    else:\n","        increasing_loss_count += 1\n","\n","    if increasing_loss_count >= EARLY_STOPPING:\n","        print(\"Early Stopping!\")\n","        break\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UcVLP0k5YOpp"},"outputs":[],"source":["%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":430},"executionInfo":{"elapsed":666,"status":"ok","timestamp":1700553227056,"user":{"displayName":"오승옥","userId":"16243407126970040843"},"user_tz":-540},"id":"BEWgFQLaYOpp","outputId":"00a09257-94ac-42e3-c17c-fc4cdc20a172"},"outputs":[],"source":["plt.plot(range(len(train_losses)), train_losses, label=\"Training Loss\")\n","plt.plot(range(len(val_losses)), val_losses, label=\"Validation Loss\")\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"olDIlrtEZ26x"},"outputs":[],"source":["directory = 'models'\n","os.makedirs(directory, exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GYi4GKp4YOpp"},"outputs":[],"source":["torch.save(model.state_dict(), 'models/model.pt')"]},{"cell_type":"markdown","metadata":{"id":"TtVQtSwXe3e-"},"source":["## Inference\n","\n","The code below is used to inference the model and submit the result to the competition."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1700553227057,"user":{"displayName":"오승옥","userId":"16243407126970040843"},"user_tz":-540},"id":"reCcxevIdVPH","outputId":"15e21153-99c8-4fd1-ae00-1fcae70e772f"},"outputs":[],"source":["# Load the model\n","\n","model.load_state_dict( torch.load('models/model.pt') )\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Wh2kE94dYPp"},"outputs":[],"source":["# testdata = pd.read_csv('/content/drive/MyDrive/data/Tdata10.csv')\n","testdata = pd.read_csv('/content/drive/MyDrive/data/Tdata17.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xlWXQckyd7FJ"},"outputs":[],"source":["features_test = testdata\n","labels_test = pd.DataFrame({'label': [0] * len(testdata)})\n","test_dataset = SunlightDataset(features_test, labels_test)\n","test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1700553227545,"user":{"displayName":"오승옥","userId":"16243407126970040843"},"user_tz":-540},"id":"N3vbZAbGeF6p","outputId":"003d4b52-9a97-4f64-e8ee-c14b651e453c"},"outputs":[],"source":["# get number of rows in testdata\n","num_test = len(testdata)\n","num_test"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1700553227545,"user":{"displayName":"오승옥","userId":"16243407126970040843"},"user_tz":-540},"id":"rftxpBXWeJD-","outputId":"59a66e91-b867-4bb8-88f8-f5f6aa9be22e"},"outputs":[],"source":["next(iter(test_loader))[0].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1700553227545,"user":{"displayName":"오승옥","userId":"16243407126970040843"},"user_tz":-540},"id":"cx3xzQOXeI9f","outputId":"d208f5bb-294d-4ea5-9e9a-8d0149bf69cf"},"outputs":[],"source":["y_pred = [[] for _ in range(num_test)]\n","len(y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tAaLQuhNeIzc"},"outputs":[],"source":["# test phase\n","model.eval()\n","\n","with torch.no_grad():\n","    for i, (features, labels) in enumerate(test_loader):\n","        features = features.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = model(features).squeeze(-1)\n","        outputs[outputs < 0] = 0\n","\n","        for seq_idx in range(outputs.shape[-1]):\n","            y_pred[i + seq_idx].append(outputs[:,seq_idx].item())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hk7tYe2-dYF0"},"outputs":[],"source":["y_pred = [sum(y_pred[i]) / len(y_pred[i]) for i in range(len(y_pred))]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uo-wElA8dYDe"},"outputs":[],"source":["y_pred_pd = pd.DataFrame(y_pred)\n","y_pred_pd.to_csv('solar.csv', index=False)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.18"}},"nbformat":4,"nbformat_minor":0}
